{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import json\n",
    "from underthesea import word_tokenize\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import datasets\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "\n",
    "import re\n",
    "\n",
    "import transformers\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, TrainingArguments, Trainer\n",
    "\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"data/train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[df[\"evidence\"].notna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"evidence_start\"] = df.apply(lambda x: x[\"context\"].find(x[\"evidence\"]), axis=1)\n",
    "df[\"evidence_end\"] = df.apply(lambda x: x[\"evidence_start\"] + len(x[\"evidence\"]), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import PreTrainedTokenizerFast, AutoModelForQuestionAnswering, AutoTokenizer\n",
    "model = AutoModelForQuestionAnswering.from_pretrained(\"nguyenvulebinh/vi-mrc-base\")\n",
    "# model.to(device)\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"nguyenvulebinh/vi-mrc-base\")\n",
    "# tokenizer.add_special_tokens({'pad_token': '[PAD]'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train, df_val = train_test_split(df, test_size=0.05, random_state=42)\n",
    "df_train = df_train.reset_index(drop=True)\n",
    "df_val = df_val.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = datasets.Dataset.from_pandas(df_train)\n",
    "val_dataset = datasets.Dataset.from_pandas(df_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_function(examples):\n",
    "    questions = [q.strip() for q in examples[\"claim\"]]\n",
    "    inputs = tokenizer(\n",
    "        questions,\n",
    "        examples[\"context\"],\n",
    "        max_length=384,\n",
    "        truncation=\"only_second\",\n",
    "        return_offsets_mapping=True,\n",
    "        padding=\"max_length\",\n",
    "        \n",
    "    )\n",
    "\n",
    "    offset_mapping = inputs.pop(\"offset_mapping\")\n",
    "    answers = examples[\"evidence\"]\n",
    "    start_positions = []\n",
    "    end_positions = []\n",
    "\n",
    "    for i, offset in enumerate(offset_mapping):\n",
    "        answer = answers[i]\n",
    "        start_char = examples[\"evidence_start\"][i]\n",
    "        end_char = examples[\"evidence_end\"][i]\n",
    "        sequence_ids = inputs.sequence_ids(i)\n",
    "\n",
    "        # Find the start and end of the context\n",
    "        idx = 0\n",
    "        while sequence_ids[idx] != 1:\n",
    "            idx += 1\n",
    "        context_start = idx\n",
    "        while sequence_ids[idx] == 1:\n",
    "            idx += 1\n",
    "        context_end = idx - 1\n",
    "\n",
    "        # If the answer is not fully inside the context, label it (0, 0)\n",
    "        if offset[context_start][0] > end_char or offset[context_end][1] < start_char:\n",
    "            start_positions.append(0)\n",
    "            end_positions.append(0)\n",
    "        else:\n",
    "            # Otherwise it's the start and end token positions\n",
    "            idx = context_start\n",
    "            while idx <= context_end and offset[idx][0] <= start_char:\n",
    "                idx += 1\n",
    "            start_positions.append(idx - 1)\n",
    "\n",
    "            idx = context_end\n",
    "            while idx >= context_start and offset[idx][1] >= end_char:\n",
    "                idx -= 1\n",
    "            end_positions.append(idx + 1)\n",
    "\n",
    "    inputs[\"start_positions\"] = start_positions\n",
    "    inputs[\"end_positions\"] = end_positions\n",
    "    return inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6ca2d2dfb1d64b9e8fbbb6f66d667948",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/23738 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "515553dce08648c391e8b5e5fd503778",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1250 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_datasets = train_dataset.map(preprocess_function,batched=True, batch_size=32,remove_columns=train_dataset.column_names)\n",
    "valid_datasets = val_dataset.map(preprocess_function,batched=True, batch_size=32,remove_columns=val_dataset.column_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = train_datasets[10]\n",
    "envidence = sample[\"input_ids\"][sample[\"start_positions\"]:sample[\"end_positions\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'context': 'chủ tịch quốc hội vương đình huệ thăm chính thức uruguay đến ngày 28/4, theo lời mời của chủ tịch thượng viện nước này beatriz argimon cedeira. đây là chuyến thăm cấp cao đầu tiên của việt nam tới uruguay, vào dịp kỷ niệm 30 năm thiết lập quan hệ ngoại giao giữa hai nước.\\n\\ntrong chuyến thăm, chủ tịch quốc hội vương đình huệ dự kiến hội đàm, hội kiến với lãnh đạo uruguay, ký thỏa thuận hợp tác giữa cơ quan lập pháp hai nước, dự một số hoạt động kỷ niệm 30 năm thiết lập quan hệ ngoại giao việt nam - uruguay.\\n\\nviệt nam và uruguay thiết lập quan hệ ngoại giao ngày 11/8/1993. trong 30 năm qua, quan hệ hữu nghị và hợp tác giữa hai nước đã phát triển, trao đổi thương mại hai chiều tăng từ 27 triệu usd năm 2007 lên hơn 100 triệu usd năm 2019. do tác động của đại dịch covid-19, trao đổi thương mại giảm phần nào, nhưng sang năm 2022, kim ngạch hai chiều đã tăng gần 90% so với năm 2021, đạt hơn 175 triệu usd.\\n\\nhai nước ủng hộ lẫn nhau tại các diễn đàn khu vực và quốc tế, phát huy vai trò của cơ quan lập pháp trong thúc đẩy quan hệ song phương, tạo điều kiện hỗ trợ cộng đồng doanh nghiệp cũng như người dân sinh sống, học tập, đầu tư và kinh doanh tại mỗi nước.\\n\\nviệt nam và uruguay còn nhiều tiềm năng hợp tác trong các lĩnh vực chăn nuôi đại gia súc, công nghiệp chế biến nông thủy sản, công nghệ sinh học - di truyền, công nghệ thông tin, quản lý xây dựng.\\n\\ntrước đó, chủ tịch quốc hội đã thăm cuba từ ngày 18 đến 23/4 và argentina từ ngày 23/4 đến 26/4. đây là chuyến thăm cấp cao nhất của lãnh đạo việt nam đến mỹ latinh trong năm 2023 nhằm mở rộng quan hệ, thúc đẩy hợp tác với các đối tác khu vực này.\\n\\nnhư tâm',\n",
       " 'claim': 'chuyến thăm của chủ tịch quốc hội đã thăm cuba là chuyến thăm cấp cao nhất của lãnh đạo việt nam đến hoa kỳ trong năm 2023 ',\n",
       " 'verdict': 'REFUTED',\n",
       " 'evidence': 'Đây là chuyến thăm cấp cao nhất của lãnh đạo Việt Nam đến Mỹ Latinh trong năm 2023 nhằm mở rộng quan hệ, thúc đẩy hợp tác với các đối tác khu vực này.',\n",
       " 'context_tokenizer': 'chủ_tịch quốc_hội vương_đình huệ thăm chính_thức uruguay đến ngày 28/4 , theo lời mời của chủ_tịch thượng_viện nước này beatriz argimon cedeira . đây là chuyến thăm cấp cao đầu_tiên của việt_nam tới uruguay , vào dịp kỷ_niệm 30 năm thiết_lập quan_hệ ngoại_giao giữa hai nước . trong chuyến thăm , chủ_tịch quốc_hội vương_đình_huệ dự_kiến hội_đàm , hội_kiến với lãnh_đạo uruguay , ký thỏa_thuận hợp_tác giữa cơ_quan lập_pháp hai nước , dự một_số hoạt_động kỷ_niệm 30 năm thiết_lập quan_hệ ngoại_giao việt_nam - uruguay . việt_nam và uruguay thiết_lập quan_hệ ngoại_giao ngày 11/8/1993 . trong 30 năm qua , quan_hệ hữu_nghị và hợp_tác giữa hai nước đã phát_triển , trao_đổi thương_mại hai chiều tăng từ 27 triệu usd năm 2007 lên hơn 100 triệu usd năm 2019 . do tác_động của đại_dịch covid-19 , trao_đổi thương_mại giảm phần_nào , nhưng sang năm 2022 , kim_ngạch hai chiều đã tăng gần 90 % so với năm 2021 , đạt hơn 175 triệu usd . hai nước ủng_hộ lẫn nhau tại các diễn_đàn khu_vực và quốc_tế , phát_huy vai_trò của cơ_quan lập_pháp trong thúc_đẩy quan_hệ song_phương , tạo điều_kiện hỗ_trợ cộng_đồng doanh_nghiệp cũng như người_dân sinh_sống , học_tập , đầu_tư và kinh_doanh tại mỗi nước . việt_nam và uruguay còn nhiều tiềm_năng hợp_tác trong các lĩnh_vực chăn_nuôi đại_gia_súc , công_nghiệp chế_biến nông_thủy_sản , công_nghệ_sinh_học - di_truyền , công_nghệ_thông_tin , quản_lý xây_dựng . trước đó , chủ_tịch quốc_hội đã thăm cuba từ ngày 18 đến 23/4 và argentina từ ngày 23/4 đến 26/4 . đây là chuyến thăm cấp cao nhất của lãnh_đạo việt_nam đến mỹ_latinh trong năm 2023 nhằm mở_rộng quan_hệ , thúc_đẩy hợp_tác với các đối_tác khu_vực này . như tâm',\n",
       " 'claim_tokenizer': 'chuyến thăm của chủ_tịch quốc_hội đã thăm cuba là chuyến thăm cấp cao nhất của lãnh_đạo việt_nam đến hoa_kỳ trong năm 2023',\n",
       " 'top_tfdif': 'đây là chuyến thăm cấp cao nhất của lãnh_đạo việt_nam đến mỹ_latinh trong năm 2023 nhằm mở_rộng quan_hệ , thúc_đẩy hợp_tác với các đối_tác khu_vực này \\nđây là chuyến thăm cấp cao đầu_tiên của việt_nam tới uruguay , vào dịp kỷ_niệm 30 năm thiết_lập quan_hệ ngoại_giao giữa hai nước \\ntrong chuyến thăm , chủ_tịch quốc_hội vương_đình_huệ dự_kiến hội_đàm , hội_kiến với lãnh_đạo uruguay , ký thỏa_thuận hợp_tác giữa cơ_quan lập_pháp hai nước , dự một_số hoạt_động kỷ_niệm 30 năm thiết_lập quan_hệ ngoại_giao việt_nam - uruguay \\ntrước đó , chủ_tịch quốc_hội đã thăm cuba từ ngày 18 đến 23/4 và argentina từ ngày 23/4 đến 26/4 \\nchủ_tịch quốc_hội vương_đình huệ thăm chính_thức uruguay đến ngày 28/4 , theo lời mời của chủ_tịch thượng_viện nước này beatriz argimon cedeira ',\n",
       " 'top_bm25': 'đây là chuyến thăm cấp cao nhất của lãnh_đạo việt_nam đến mỹ_latinh trong năm 2023 nhằm mở_rộng quan_hệ , thúc_đẩy hợp_tác với các đối_tác khu_vực này \\nđây là chuyến thăm cấp cao đầu_tiên của việt_nam tới uruguay , vào dịp kỷ_niệm 30 năm thiết_lập quan_hệ ngoại_giao giữa hai nước \\ntrước đó , chủ_tịch quốc_hội đã thăm cuba từ ngày 18 đến 23/4 và argentina từ ngày 23/4 đến 26/4 \\ntrong chuyến thăm , chủ_tịch quốc_hội vương_đình_huệ dự_kiến hội_đàm , hội_kiến với lãnh_đạo uruguay , ký thỏa_thuận hợp_tác giữa cơ_quan lập_pháp hai nước , dự một_số hoạt_động kỷ_niệm 30 năm thiết_lập quan_hệ ngoại_giao việt_nam - uruguay \\nchủ_tịch quốc_hội vương_đình huệ thăm chính_thức uruguay đến ngày 28/4 , theo lời mời của chủ_tịch thượng_viện nước này beatriz argimon cedeira ',\n",
       " 'verdict_label': 1,\n",
       " 'evidence_start': -1,\n",
       " 'evidence_end': 149}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset[10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'</s> chủ tịch quốc hội vương đình huệ thăm chính thức uruguay đến ngày 28/4, theo lời mời của chủ tịch thượng viện nước này beatriz argimon cedeira. đây'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(envidence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import DefaultDataCollator\n",
    "\n",
    "data_collator = DefaultDataCollator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/bbsw/Data1/Hung-ws/lazy/v2/.venv/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1606' max='3710' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1606/3710 18:21 < 24:05, 1.46 it/s, Epoch 4.33/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>3.926900</td>\n",
       "      <td>1.928491</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>1.844500</td>\n",
       "      <td>1.792933</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>750</td>\n",
       "      <td>1.758700</td>\n",
       "      <td>1.760567</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>1.645300</td>\n",
       "      <td>1.602615</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1250</td>\n",
       "      <td>1.586900</td>\n",
       "      <td>1.554161</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>1.543000</td>\n",
       "      <td>1.523248</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/bbsw/Data1/Hung-ws/lazy/v2/.venv/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/media/bbsw/Data1/Hung-ws/lazy/v2/.venv/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/media/bbsw/Data1/Hung-ws/lazy/v2/.venv/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/media/bbsw/Data1/Hung-ws/lazy/v2/trainevident.ipynb Cell 14\u001b[0m line \u001b[0;36m2\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bbbsw/media/bbsw/Data1/Hung-ws/lazy/v2/trainevident.ipynb#X16sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m training_args \u001b[39m=\u001b[39m TrainingArguments(\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bbbsw/media/bbsw/Data1/Hung-ws/lazy/v2/trainevident.ipynb#X16sdnNjb2RlLXJlbW90ZQ%3D%3D?line=1'>2</a>\u001b[0m     output_dir\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mmodels/evidence\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bbbsw/media/bbsw/Data1/Hung-ws/lazy/v2/trainevident.ipynb#X16sdnNjb2RlLXJlbW90ZQ%3D%3D?line=2'>3</a>\u001b[0m     num_train_epochs\u001b[39m=\u001b[39m\u001b[39m10\u001b[39m,              \u001b[39m# total number of training epochs\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bbbsw/media/bbsw/Data1/Hung-ws/lazy/v2/trainevident.ipynb#X16sdnNjb2RlLXJlbW90ZQ%3D%3D?line=15'>16</a>\u001b[0m     fp16\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m,\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bbbsw/media/bbsw/Data1/Hung-ws/lazy/v2/trainevident.ipynb#X16sdnNjb2RlLXJlbW90ZQ%3D%3D?line=16'>17</a>\u001b[0m )\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bbbsw/media/bbsw/Data1/Hung-ws/lazy/v2/trainevident.ipynb#X16sdnNjb2RlLXJlbW90ZQ%3D%3D?line=18'>19</a>\u001b[0m trainer \u001b[39m=\u001b[39m Trainer(\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bbbsw/media/bbsw/Data1/Hung-ws/lazy/v2/trainevident.ipynb#X16sdnNjb2RlLXJlbW90ZQ%3D%3D?line=19'>20</a>\u001b[0m     model\u001b[39m=\u001b[39mmodel,\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bbbsw/media/bbsw/Data1/Hung-ws/lazy/v2/trainevident.ipynb#X16sdnNjb2RlLXJlbW90ZQ%3D%3D?line=20'>21</a>\u001b[0m     args\u001b[39m=\u001b[39mtraining_args,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bbbsw/media/bbsw/Data1/Hung-ws/lazy/v2/trainevident.ipynb#X16sdnNjb2RlLXJlbW90ZQ%3D%3D?line=24'>25</a>\u001b[0m     data_collator\u001b[39m=\u001b[39mdata_collator,\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bbbsw/media/bbsw/Data1/Hung-ws/lazy/v2/trainevident.ipynb#X16sdnNjb2RlLXJlbW90ZQ%3D%3D?line=25'>26</a>\u001b[0m )\n\u001b[0;32m---> <a href='vscode-notebook-cell://ssh-remote%2Bbbsw/media/bbsw/Data1/Hung-ws/lazy/v2/trainevident.ipynb#X16sdnNjb2RlLXJlbW90ZQ%3D%3D?line=27'>28</a>\u001b[0m trainer\u001b[39m.\u001b[39;49mtrain()\n",
      "File \u001b[0;32m/media/bbsw/Data1/Hung-ws/lazy/v2/.venv/lib/python3.10/site-packages/transformers/trainer.py:1555\u001b[0m, in \u001b[0;36mTrainer.train\u001b[0;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[1;32m   1553\u001b[0m         hf_hub_utils\u001b[39m.\u001b[39menable_progress_bars()\n\u001b[1;32m   1554\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1555\u001b[0m     \u001b[39mreturn\u001b[39;00m inner_training_loop(\n\u001b[1;32m   1556\u001b[0m         args\u001b[39m=\u001b[39;49margs,\n\u001b[1;32m   1557\u001b[0m         resume_from_checkpoint\u001b[39m=\u001b[39;49mresume_from_checkpoint,\n\u001b[1;32m   1558\u001b[0m         trial\u001b[39m=\u001b[39;49mtrial,\n\u001b[1;32m   1559\u001b[0m         ignore_keys_for_eval\u001b[39m=\u001b[39;49mignore_keys_for_eval,\n\u001b[1;32m   1560\u001b[0m     )\n",
      "File \u001b[0;32m/media/bbsw/Data1/Hung-ws/lazy/v2/.venv/lib/python3.10/site-packages/transformers/trainer.py:1865\u001b[0m, in \u001b[0;36mTrainer._inner_training_loop\u001b[0;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[1;32m   1859\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39maccelerator\u001b[39m.\u001b[39maccumulate(model):\n\u001b[1;32m   1860\u001b[0m     tr_loss_step \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtraining_step(model, inputs)\n\u001b[1;32m   1862\u001b[0m \u001b[39mif\u001b[39;00m (\n\u001b[1;32m   1863\u001b[0m     args\u001b[39m.\u001b[39mlogging_nan_inf_filter\n\u001b[1;32m   1864\u001b[0m     \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m is_torch_tpu_available()\n\u001b[0;32m-> 1865\u001b[0m     \u001b[39mand\u001b[39;00m (torch\u001b[39m.\u001b[39misnan(tr_loss_step) \u001b[39mor\u001b[39;00m torch\u001b[39m.\u001b[39;49misinf(tr_loss_step))\n\u001b[1;32m   1866\u001b[0m ):\n\u001b[1;32m   1867\u001b[0m     \u001b[39m# if loss is nan or inf simply add the average of previous logged losses\u001b[39;00m\n\u001b[1;32m   1868\u001b[0m     tr_loss \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m tr_loss \u001b[39m/\u001b[39m (\u001b[39m1\u001b[39m \u001b[39m+\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstate\u001b[39m.\u001b[39mglobal_step \u001b[39m-\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_globalstep_last_logged)\n\u001b[1;32m   1869\u001b[0m \u001b[39melse\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir=\"models/evidence\",\n",
    "    num_train_epochs=10,              # total number of training epochs\n",
    "    learning_rate=1e-5,              # learning rate\n",
    "    per_device_train_batch_size=32,  # batch size per device during training\n",
    "    per_device_eval_batch_size=32,   # batch size for evaluation\n",
    "    # gradient_accumulation_steps=2,   # Number of updates steps to accumulate before performing a backward/update pass.\n",
    "    warmup_steps=250,                # number of warmup steps for learning rate scheduler\n",
    "    weight_decay=0.01,               # strength of weight decay\n",
    "    logging_dir='./logs',            # directory for storing logs\n",
    "    logging_steps=250,\n",
    "    eval_steps=250,\n",
    "    evaluation_strategy='steps',\n",
    "    load_best_model_at_end=True,\n",
    "    greater_is_better=True,\n",
    "    fp16=True,\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_datasets,\n",
    "    eval_dataset=valid_datasets,\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=data_collator,\n",
    ")\n",
    "\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForQuestionAnswering, TrainingArguments, Trainer\n",
    "model = AutoModelForQuestionAnswering.from_pretrained(\"/media/bbsw/Data1/Hung-ws/lazy/v2/models/evidence/checkpoint-500\")\n",
    "model.to(device)\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"/media/bbsw/Data1/Hung-ws/lazy/v2/models/evidence/checkpoint-500\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "claim = df_val[\"claim\"][10]\n",
    "context = df_val[\"context\"][10]\n",
    "evidence = df_val[\"evidence\"][10]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = tokenizer.encode_plus(claim, context, return_tensors=\"pt\", truncation=True).to(device)\n",
    "with torch.no_grad():\n",
    "    outputs = model(**inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "answer_start_index = outputs.start_logits.argmax()\n",
    "answer_end_index = outputs.end_logits.argmax()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(28, device='cuda:0'), tensor(53, device='cuda:0'))"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answer_start_index,answer_end_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'</s> tại buổi tiếp xúc công nhân với đại biểu quốc hội ngày 12/5, ông nguyễn văn tân, chủ tịch công đoàn'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_answer_tokens =inputs.input_ids[0, answer_start_index : answer_end_index + 1]\n",
    "tokenizer.decode(predict_answer_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Danh sách sau đó công khai trên cổng BHXH tỉnh hoặc phạt hành chính tùy mức độ chậm trễ của doanh nghiệp'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evidence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(12, device='cuda:0'), tensor(93, device='cuda:0'))"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answer_start_index, answer_end_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
