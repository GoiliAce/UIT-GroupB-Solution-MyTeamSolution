{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import json\n",
    "from underthesea import word_tokenize\n",
    "\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "\n",
    "\n",
    "import re\n",
    "\n",
    "import transformers\n",
    "from transformers import AutoTokenizer\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "from tqdm.notebook import tqdm\n",
    "from utils.retrieval import BM25Retrieval, TFIDFRetrieval, SentenceRetrieval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class config:\n",
    "    test_path = '/media/bbsw/Data/Hung-ws/lazy/v2/ise-dsc01-private-test-offcial.json'\n",
    "    model_name = 'models/model_v7/checkpoint-1000'\n",
    "    max_length = 256\n",
    "    batch_size = 64\n",
    "    num_workers = 32\n",
    "    check_point = 'models/model_v7/checkpoint-1000'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_json(config.test_path).transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "label2id = {'SUPPORTED': 0, 'REFUTED': 1,'NEI': 2}\n",
    "id2label = {0: 'SUPPORTED', 1:'REFUTED', 2:'NEI'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = AutoModelForSequenceClassification.from_pretrained(config.check_point, num_labels=3, label2id=label2id, id2label=id2label)\n",
    "model.to(device)\n",
    "tokenizer = AutoTokenizer.from_pretrained(config.model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['context_tokenizer'] = df['context'].apply(lambda x: word_tokenize(x.lower(), format='text'))\n",
    "df['claim_tokenizer'] = df['claim'].apply(lambda x: word_tokenize(x.lower(), format='text'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = SentenceRetrieval()\n",
    "tfidf = TFIDFRetrieval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_context(context):\n",
    "    docs = re.split(r'(?<!\\d)\\.\\s*(?![.])', context)\n",
    "    docs = [doc for doc in docs if doc]\n",
    "    return docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_context_evidence(context):\n",
    "    docs = re.split(r'\\.\\s*(?![.])', context)\n",
    "    docs = [doc for doc in docs if doc]\n",
    "    return docs\n",
    "    # docs = '\\n\\n'.join(docs)\n",
    "    # docs = docs.split('\\n\\n')\n",
    "    # return [doc.strip() for doc in docs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_topk(query, context, k=5, option=sentences, isProcessbar=False):\n",
    "    if isProcessbar:\n",
    "        global pbar\n",
    "        pbar.update(1)\n",
    "    docs =split_context(context)\n",
    "\n",
    "    return '\\n'.join(option.get_topk(query, docs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bcff9a1609ca4e678222cf21fadfae01",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5396 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pbar = tqdm(total=len(df))\n",
    "# df['top_similarity'] = df.apply(lambda x: get_topk(x['claim_tokenizer'], x['context_tokenizer'], option=sentences, k=5, isProcessbar=True), axis=1)\n",
    "df['top_tfdif'] = df.apply(lambda x: get_topk(x['claim_tokenizer'], x['context_tokenizer'], option=tfidf, k=5, isProcessbar=True), axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = pd.read_csv('data/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>context</th>\n",
       "      <th>claim</th>\n",
       "      <th>context_tokenizer</th>\n",
       "      <th>claim_tokenizer</th>\n",
       "      <th>top_tfdif</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>39773</th>\n",
       "      <td>Sáng 7/6, bà Nguyễn Thị Lệ Thanh, Giám đốc Sở ...</td>\n",
       "      <td>Xuyên suốt thời gian diễn ra Festival biển Nha...</td>\n",
       "      <td>sáng 7/6 , bà nguyễn_thị_lệ_thanh , giám_đốc s...</td>\n",
       "      <td>xuyên suốt thời_gian diễn ra festival biển nha...</td>\n",
       "      <td>người đứng đầu sở du_lịch khánh_hòa cho_hay , ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37657</th>\n",
       "      <td>Còn với Công nghệ dệt may, em không biết may h...</td>\n",
       "      <td>Một số người khuyên Nhi Pham theo Công nghệ th...</td>\n",
       "      <td>còn với công_nghệ dệt_may , em không biết may ...</td>\n",
       "      <td>một_số người khuyên_nhi pham theo công_nghệ th...</td>\n",
       "      <td>một_số người khuyên em theo công_nghệ thực_phẩ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40265</th>\n",
       "      <td>Nhà nghiên cứu Guangming Tao ở Đại học Khoa họ...</td>\n",
       "      <td>Nhiệt độ da bên dưới lớp cotton cao làm người ...</td>\n",
       "      <td>nhà_nghiên_cứu guangming tao ở đại_học khoa_họ...</td>\n",
       "      <td>nhiệt_độ da bên dưới lớp cotton cao làm người ...</td>\n",
       "      <td>nhiệt_độ da bên dưới vải siêu_mát tăng từ khoả...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47711</th>\n",
       "      <td>Trong không gian của du thuyền 5 sao, Shynh Ho...</td>\n",
       "      <td>Nhãn hàng sẽ cùng 6 đối tác đề ra những chiến ...</td>\n",
       "      <td>trong không_gian của du_thuyền 5 sao , shynh h...</td>\n",
       "      <td>nhãn hàng sẽ cùng 6 đối_tác đề ra những chiến_...</td>\n",
       "      <td>nhãn hàng sẽ cùng đối_tác đề ra những chiến_lư...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39930</th>\n",
       "      <td>Pin sinh học là giải pháp mới để cung cấp năng...</td>\n",
       "      <td>Bụi thông minh chỉ cần 5 tế bào vi khuẩn cũng ...</td>\n",
       "      <td>pin sinh_học là giải_pháp mới để cung_cấp năng...</td>\n",
       "      <td>bụi thông_minh chỉ cần 5 tế_bào vi_khuẩn cũng ...</td>\n",
       "      <td>\" chúng_tôi gọi đó là ' bụi thông_minh ' và ch...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 context  \\\n",
       "39773  Sáng 7/6, bà Nguyễn Thị Lệ Thanh, Giám đốc Sở ...   \n",
       "37657  Còn với Công nghệ dệt may, em không biết may h...   \n",
       "40265  Nhà nghiên cứu Guangming Tao ở Đại học Khoa họ...   \n",
       "47711  Trong không gian của du thuyền 5 sao, Shynh Ho...   \n",
       "39930  Pin sinh học là giải pháp mới để cung cấp năng...   \n",
       "\n",
       "                                                   claim  \\\n",
       "39773  Xuyên suốt thời gian diễn ra Festival biển Nha...   \n",
       "37657  Một số người khuyên Nhi Pham theo Công nghệ th...   \n",
       "40265  Nhiệt độ da bên dưới lớp cotton cao làm người ...   \n",
       "47711  Nhãn hàng sẽ cùng 6 đối tác đề ra những chiến ...   \n",
       "39930  Bụi thông minh chỉ cần 5 tế bào vi khuẩn cũng ...   \n",
       "\n",
       "                                       context_tokenizer  \\\n",
       "39773  sáng 7/6 , bà nguyễn_thị_lệ_thanh , giám_đốc s...   \n",
       "37657  còn với công_nghệ dệt_may , em không biết may ...   \n",
       "40265  nhà_nghiên_cứu guangming tao ở đại_học khoa_họ...   \n",
       "47711  trong không_gian của du_thuyền 5 sao , shynh h...   \n",
       "39930  pin sinh_học là giải_pháp mới để cung_cấp năng...   \n",
       "\n",
       "                                         claim_tokenizer  \\\n",
       "39773  xuyên suốt thời_gian diễn ra festival biển nha...   \n",
       "37657  một_số người khuyên_nhi pham theo công_nghệ th...   \n",
       "40265  nhiệt_độ da bên dưới lớp cotton cao làm người ...   \n",
       "47711  nhãn hàng sẽ cùng 6 đối_tác đề ra những chiến_...   \n",
       "39930  bụi thông_minh chỉ cần 5 tế_bào vi_khuẩn cũng ...   \n",
       "\n",
       "                                               top_tfdif  \n",
       "39773  người đứng đầu sở du_lịch khánh_hòa cho_hay , ...  \n",
       "37657  một_số người khuyên em theo công_nghệ thực_phẩ...  \n",
       "40265  nhiệt_độ da bên dưới vải siêu_mát tăng từ khoả...  \n",
       "47711  nhãn hàng sẽ cùng đối_tác đề ra những chiến_lư...  \n",
       "39930  \" chúng_tôi gọi đó là ' bụi thông_minh ' và ch...  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_sample(claim, context):\n",
    "    example_batch = tokenizer(\n",
    "        text=claim,\n",
    "        text_pair=context,\n",
    "        max_length=config.max_length,\n",
    "        padding='max_length',\n",
    "        truncation='only_second',\n",
    "        return_tensors='pt',\n",
    "    ).to(device)\n",
    "    with torch.no_grad():\n",
    "        output = model(**example_batch)\n",
    "        logits = output[0]\n",
    "    pred = id2label[logits.argmax().item()]\n",
    "    \n",
    "    return pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_text(text: str) -> str:    \n",
    "    text = re.sub(r\"['\\\",\\.\\?:\\-!]\", \"\", text)\n",
    "    text = text.strip()\n",
    "    text = \" \".join(text.split())\n",
    "    text = text.lower()\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_evident(context, claim):\n",
    "    # docs = re.split(r'(?<!\\d)\\.\\s*(?![.])', context)\n",
    "    context_list_seq = re.split(r'\\.\\s*(?![.])', context)\n",
    "    context_list_seq = [seq for seq in context_list_seq if seq]\n",
    "    context_list_seq.append(claim)\n",
    "    tfidf_vectorizer = TfidfVectorizer()\n",
    "    tfidf_matrix = tfidf_vectorizer.fit_transform( context_list_seq)\n",
    "    similarity_scores = cosine_similarity(tfidf_matrix)\n",
    "    similarity_with_last = cosine_similarity(tfidf_matrix[-1:], tfidf_matrix[:-1])\n",
    "\n",
    "    evident_idx = np.argsort(similarity_with_last[0])[::-1][0]\n",
    "    evident = context_list_seq[evident_idx]\n",
    "    return evident"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cd901dab12c142448a5343a2ef99bd0a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5396 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "result = {}\n",
    "process_bar = tqdm(total=len(df))\n",
    "for row in df.iterrows():\n",
    "    idx = str(row[0])\n",
    "    claim_tokenizer = row[1]['claim_tokenizer']\n",
    "    context_tokenizer = row[1]['context_tokenizer']\n",
    "    claim = row[1]['claim']\n",
    "    context = row[1]['context']\n",
    "    docs = row[1]['top_tfdif']\n",
    "    label = predict_sample(claim_tokenizer, docs)\n",
    "    if label == 'NEI':\n",
    "        evidence = \"\"\n",
    "    else:\n",
    "        evidence = preprocess_text(tfidf.get_topk(claim, split_context_evidence(context), k=1)[0])\n",
    "    result[idx] = {\n",
    "        \"verdict\": label,\n",
    "        \"evidence\": evidence\n",
    "    }\n",
    "    process_bar.update(1)\n",
    "\n",
    "with open('private_result.json', 'w') as f:\n",
    "    json.dump(result, f, indent=4, ensure_ascii=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "updating: private_result.json (deflated 75%)\n"
     ]
    }
   ],
   "source": [
    "!zip -r results.zip private_result.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
